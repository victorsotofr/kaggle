{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import get_train_data\n",
    "from FeatureEngineering import _encode\n",
    "# We will do categorical encoding, and not use the integrated module of XGBoost\n",
    "# supposed to handle these categorical variables\n",
    "\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Setup__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the data:\n",
    "X, y = get_train_data()\n",
    "\n",
    "# We put the label to the log to help the model:\n",
    "X_encoded, y_log = _encode(X, y)\n",
    "\n",
    "# Pipeline creation:\n",
    "model = XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Optuna__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/kaggle_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    # Split the data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_encoded, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Hyperparameter search space\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10)\n",
    "    }\n",
    "\n",
    "    # Train XGBoost\n",
    "    model = XGBRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    preds = model.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, preds, squared=False)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Optimization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 18:19:06,650] A new study created in memory with name: no-name-2271a8e8-b98c-403e-83c8-67d471366b67\n",
      "[I 2025-01-03 18:19:12,903] Trial 0 finished with value: 0.13421888123332854 and parameters: {'n_estimators': 902, 'learning_rate': 0.010069276755047376, 'max_depth': 4}. Best is trial 0 with value: 0.13421888123332854.\n",
      "[I 2025-01-03 18:19:20,856] Trial 1 finished with value: 0.14680070953055216 and parameters: {'n_estimators': 613, 'learning_rate': 0.015407733433225724, 'max_depth': 7}. Best is trial 0 with value: 0.13421888123332854.\n",
      "[I 2025-01-03 18:19:24,168] Trial 2 finished with value: 0.1375309058542543 and parameters: {'n_estimators': 476, 'learning_rate': 0.014372390857423646, 'max_depth': 4}. Best is trial 0 with value: 0.13421888123332854.\n",
      "[I 2025-01-03 18:19:25,968] Trial 3 finished with value: 0.12847630007473865 and parameters: {'n_estimators': 344, 'learning_rate': 0.04219287557979192, 'max_depth': 3}. Best is trial 3 with value: 0.12847630007473865.\n",
      "[I 2025-01-03 18:19:33,293] Trial 4 finished with value: 0.15063554403890514 and parameters: {'n_estimators': 717, 'learning_rate': 0.08065141996998443, 'max_depth': 8}. Best is trial 3 with value: 0.12847630007473865.\n",
      "[I 2025-01-03 18:19:43,995] Trial 5 finished with value: 0.14906707519844054 and parameters: {'n_estimators': 584, 'learning_rate': 0.08346409320005257, 'max_depth': 7}. Best is trial 3 with value: 0.12847630007473865.\n",
      "[I 2025-01-03 18:20:09,108] Trial 6 finished with value: 0.13554951106842034 and parameters: {'n_estimators': 732, 'learning_rate': 0.06659095107763383, 'max_depth': 5}. Best is trial 3 with value: 0.12847630007473865.\n",
      "[I 2025-01-03 18:20:12,084] Trial 7 finished with value: 0.1522363994392389 and parameters: {'n_estimators': 230, 'learning_rate': 0.19843440896993073, 'max_depth': 8}. Best is trial 3 with value: 0.12847630007473865.\n",
      "[I 2025-01-03 18:20:13,413] Trial 8 finished with value: 0.14448527757112095 and parameters: {'n_estimators': 132, 'learning_rate': 0.027232145735872616, 'max_depth': 5}. Best is trial 3 with value: 0.12847630007473865.\n",
      "[I 2025-01-03 18:20:15,089] Trial 9 finished with value: 0.13164456120344925 and parameters: {'n_estimators': 297, 'learning_rate': 0.09088839880102892, 'max_depth': 4}. Best is trial 3 with value: 0.12847630007473865.\n",
      "[I 2025-01-03 18:20:24,518] Trial 10 finished with value: 0.14990874868409668 and parameters: {'n_estimators': 392, 'learning_rate': 0.0341624056064891, 'max_depth': 10}. Best is trial 3 with value: 0.12847630007473865.\n",
      "[I 2025-01-03 18:20:26,192] Trial 11 finished with value: 0.12827715934003175 and parameters: {'n_estimators': 322, 'learning_rate': 0.18670810132917573, 'max_depth': 3}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:20:28,331] Trial 12 finished with value: 0.13781187703773756 and parameters: {'n_estimators': 344, 'learning_rate': 0.2547430494485182, 'max_depth': 3}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:20:29,139] Trial 13 finished with value: 0.13308895067307083 and parameters: {'n_estimators': 100, 'learning_rate': 0.16522857782716144, 'max_depth': 3}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:20:36,249] Trial 14 finished with value: 0.13755468838737425 and parameters: {'n_estimators': 427, 'learning_rate': 0.0407498484245308, 'max_depth': 5}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:20:37,643] Trial 15 finished with value: 0.1307000117497708 and parameters: {'n_estimators': 250, 'learning_rate': 0.12671647857978463, 'max_depth': 3}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:20:41,535] Trial 16 finished with value: 0.1389628379288649 and parameters: {'n_estimators': 506, 'learning_rate': 0.046989767770171345, 'max_depth': 6}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:20:47,500] Trial 17 finished with value: 0.15223058700748593 and parameters: {'n_estimators': 182, 'learning_rate': 0.026291174869316158, 'max_depth': 10}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:20:49,768] Trial 18 finished with value: 0.14028510493880098 and parameters: {'n_estimators': 338, 'learning_rate': 0.2888445278764623, 'max_depth': 3}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:20:54,297] Trial 19 finished with value: 0.13757925458999612 and parameters: {'n_estimators': 952, 'learning_rate': 0.13615796962690013, 'max_depth': 6}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:20:57,612] Trial 20 finished with value: 0.1339378701196951 and parameters: {'n_estimators': 707, 'learning_rate': 0.0574607388999021, 'max_depth': 4}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:20:59,074] Trial 21 finished with value: 0.13231321996203577 and parameters: {'n_estimators': 254, 'learning_rate': 0.12068134961812914, 'max_depth': 3}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:21:00,102] Trial 22 finished with value: 0.13187861932353395 and parameters: {'n_estimators': 203, 'learning_rate': 0.11517919366973976, 'max_depth': 3}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:21:02,330] Trial 23 finished with value: 0.1377472092021431 and parameters: {'n_estimators': 415, 'learning_rate': 0.202173570528175, 'max_depth': 4}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:21:04,802] Trial 24 finished with value: 0.13607871213197584 and parameters: {'n_estimators': 293, 'learning_rate': 0.16629831090479447, 'max_depth': 5}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:21:06,585] Trial 25 finished with value: 0.1310879622682724 and parameters: {'n_estimators': 361, 'learning_rate': 0.09734958750679454, 'max_depth': 3}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:21:09,407] Trial 26 finished with value: 0.12895965064215698 and parameters: {'n_estimators': 495, 'learning_rate': 0.05833024674588106, 'max_depth': 4}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:21:12,668] Trial 27 finished with value: 0.13383839018756177 and parameters: {'n_estimators': 474, 'learning_rate': 0.02085005288199351, 'max_depth': 4}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:21:16,531] Trial 28 finished with value: 0.13570037054306802 and parameters: {'n_estimators': 573, 'learning_rate': 0.060095662638769504, 'max_depth': 5}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:21:19,745] Trial 29 finished with value: 0.133126617420048 and parameters: {'n_estimators': 648, 'learning_rate': 0.04147975578189367, 'max_depth': 4}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:21:27,758] Trial 30 finished with value: 0.1377502996220105 and parameters: {'n_estimators': 525, 'learning_rate': 0.031026158828403847, 'max_depth': 6}. Best is trial 11 with value: 0.12827715934003175.\n",
      "[I 2025-01-03 18:21:29,659] Trial 31 finished with value: 0.12349490722911001 and parameters: {'n_estimators': 291, 'learning_rate': 0.07256489894558181, 'max_depth': 3}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:21:33,808] Trial 32 finished with value: 0.1286742846974339 and parameters: {'n_estimators': 813, 'learning_rate': 0.046958119486068546, 'max_depth': 3}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:21:38,532] Trial 33 finished with value: 0.13272698402925853 and parameters: {'n_estimators': 931, 'learning_rate': 0.011073348167557812, 'max_depth': 3}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:21:42,536] Trial 34 finished with value: 0.12833931227281947 and parameters: {'n_estimators': 846, 'learning_rate': 0.021429122272200216, 'max_depth': 3}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:21:50,335] Trial 35 finished with value: 0.13414732059537018 and parameters: {'n_estimators': 831, 'learning_rate': 0.01698892972341473, 'max_depth': 4}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:22:07,663] Trial 36 finished with value: 0.15157018700051827 and parameters: {'n_estimators': 998, 'learning_rate': 0.020479906297752176, 'max_depth': 9}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:22:08,870] Trial 37 finished with value: 0.19350856471554329 and parameters: {'n_estimators': 178, 'learning_rate': 0.010660090701219455, 'max_depth': 3}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:22:13,936] Trial 38 finished with value: 0.14926411042250337 and parameters: {'n_estimators': 447, 'learning_rate': 0.07106910219789213, 'max_depth': 8}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:22:15,673] Trial 39 finished with value: 0.13731668789429688 and parameters: {'n_estimators': 295, 'learning_rate': 0.019649430957915773, 'max_depth': 5}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:22:22,106] Trial 40 finished with value: 0.13488410472107787 and parameters: {'n_estimators': 622, 'learning_rate': 0.013660422722637813, 'max_depth': 4}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:22:29,859] Trial 41 finished with value: 0.1285361662234032 and parameters: {'n_estimators': 732, 'learning_rate': 0.04663916594684961, 'max_depth': 3}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:22:34,309] Trial 42 finished with value: 0.13235717629105798 and parameters: {'n_estimators': 815, 'learning_rate': 0.07883072692291077, 'max_depth': 3}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:22:46,501] Trial 43 finished with value: 0.12999817658423052 and parameters: {'n_estimators': 868, 'learning_rate': 0.025607381432384013, 'max_depth': 3}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:23:06,103] Trial 44 finished with value: 0.1337623332081278 and parameters: {'n_estimators': 780, 'learning_rate': 0.03905563684306753, 'max_depth': 4}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:23:26,079] Trial 45 finished with value: 0.13534788911616233 and parameters: {'n_estimators': 700, 'learning_rate': 0.034449421889473475, 'max_depth': 4}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:23:32,685] Trial 46 finished with value: 0.12985315059844466 and parameters: {'n_estimators': 879, 'learning_rate': 0.04721460628160952, 'max_depth': 3}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:23:40,761] Trial 47 finished with value: 0.1319346675579454 and parameters: {'n_estimators': 766, 'learning_rate': 0.0980897125526005, 'max_depth': 3}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:24:05,951] Trial 48 finished with value: 0.14506024530290146 and parameters: {'n_estimators': 667, 'learning_rate': 0.06699461371448512, 'max_depth': 7}. Best is trial 31 with value: 0.12349490722911001.\n",
      "[I 2025-01-03 18:24:09,633] Trial 49 finished with value: 0.1334293635983467 and parameters: {'n_estimators': 357, 'learning_rate': 0.031026770949383994, 'max_depth': 4}. Best is trial 31 with value: 0.12349490722911001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      " Value:  0.12349490722911001\n",
      " Params:  {'n_estimators': 291, 'learning_rate': 0.07256489894558181, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "# Create a study\n",
    "study = optuna.create_study(direction='minimize')  # 'minimize' for RMSE, 'maximize' for accuracy, etc.\n",
    "\n",
    "# Optimize\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best trial:\")\n",
    "print(\" Value: \", study.best_value)\n",
    "print(\" Params: \", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Test Data Prediction with Best Parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.07256489894558181,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=291, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.07256489894558181,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=291, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.07256489894558181,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=291, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIT with the best Hyperparameters from the Optuna study:\n",
    "best_params = study.best_params\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X_encoded, y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "test_data_encoded = _encode(test_data).reindex(columns=X_encoded.columns, \n",
    "                                               fill_value=0)\n",
    "\n",
    "test_prediction = best_model.predict(test_data_encoded)\n",
    "predictions = np.exp(test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Output Extraction__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    dict(\n",
    "        Id=test_data['Id'],\n",
    "        SalePrice=predictions,\n",
    "    )\n",
    ")\n",
    "results.to_csv(\"submission_XGB_vOptuna.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
